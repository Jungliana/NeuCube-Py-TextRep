{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import torch\n",
    "\n",
    "from experiments.experiment import snn_experiment, lsa_experiment\n",
    "from experiments.preprocess import Word2VecPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "cats = ['comp.graphics', 'sci.med', 'talk.politics.guns']\n",
    "newsgroups_train = fetch_20newsgroups(subset='all')\n",
    "\n",
    "text_prep = Word2VecPrep(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\Documents\\Moje dokumenty\\Studia\\Praca Magisterska\\NeuCube-Py-TextRep\\experiments\\preprocess.py:85: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  train_x = tensor(newsgroups_vectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = text_prep.preprocess_dataset(newsgroups_train)\n",
    "train_x.to(device)\n",
    "train_y.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = (newsgroups_vectors_tensor > 0)\n",
    "# mask = (newsgroups_vectors_tensor > -0.05) & (newsgroups_vectors_tensor < 0.05)\n",
    "# data_x = torch.where(mask, torch.tensor(1), torch.tensor(0))\n",
    "# data_x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:26, 18.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.7152180834129258\n",
      "[[400   4   1   0   2   2   1   3  33  12   0   8   0  13  17 195  16  62\n",
      "   27   3]\n",
      " [  6 602  72  33  30 106  25   9   9  10   1  25  14   3  20   5   0   1\n",
      "    2   0]\n",
      " [  4  69 621  89  34  96  24  12   7   4   2  10   6   0   4   0   1   0\n",
      "    2   0]\n",
      " [  0  38  72 544 115  47  52  18   8   6   1  15  58   2   2   0   3   0\n",
      "    1   0]\n",
      " [  0  35  46 142 535  42  51  10  15   2   1  10  60   3   8   0   1   1\n",
      "    0   1]\n",
      " [  1  96  82  19  30 682  18   2   6   4   1  20   8   3  10   1   2   2\n",
      "    1   0]\n",
      " [  1   6  17  47  14   6 745  35  22   9  10  11  31   3  10   1   3   0\n",
      "    4   0]\n",
      " [  6   1   2   1   1   3  25 758  92   6   3   9  28   5   5   0  30   5\n",
      "   10   0]\n",
      " [  1   6   1   1   4  12  17  95 792   4   6   2  13   9   6   2  12   3\n",
      "   10   0]\n",
      " [  5   9   4   3   2   2  14   0  10 867  58   2   0   3   0   3   0   5\n",
      "    7   0]\n",
      " [  4   2   1   2   0   3   2   0  14  18 941   5   0   1   0   1   1   1\n",
      "    3   0]\n",
      " [ 10  15   9   4   8  19   3   1   9   3   2 827  20   3   1   0  31  11\n",
      "   15   0]\n",
      " [  2  43  14  55  47  22  40  36  10   4   3  54 617  11  19   0   4   1\n",
      "    2   0]\n",
      " [ 20  16   0   0   3   3   4   1  17   5   0   3  10 873  17   6   2   1\n",
      "    9   0]\n",
      " [ 10  20   5   0   3   7   4   1  12   2   5  15   5  15 856   4   6   4\n",
      "   13   0]\n",
      " [ 44   9   4   0   1   2   2   0   4   5   1   4   0  15   7 856  12  25\n",
      "    6   0]\n",
      " [ 18   0   2   0   2   6  10   4  20   1   3  24   3   8   5   5 707  41\n",
      "   51   0]\n",
      " [ 38   4   2   0   0   3   0   0  13   9   0   7   0   4   4  16  23 790\n",
      "   27   0]\n",
      " [ 35   3   1   2   0   2   1   7  15   9   7  23   1  19  14  10 136  46\n",
      "  444   0]\n",
      " [118   6   1   0   1   4   0   0  11   6   0   5   0  20  11 297  84  22\n",
      "   20  22]]\n"
     ]
    }
   ],
   "source": [
    "lsa_experiment(train_x, train_y, clf_type=\"regression\", splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [10:37, 79.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- CLASSIFIER: random_forest ----\n",
      "acc: 0.675952456754749\n",
      "[[445   2   0   0   1   3   1   6  30  13   1  15   0  17  14 137  27  43\n",
      "   24  20]\n",
      " [  9 561 100  33  27  91  46  13  10   4   2  23  14   4  26   3   3   2\n",
      "    1   1]\n",
      " [  1  88 607  84  33  85  26   7  12   3   2  20   4   1   9   0   2   0\n",
      "    0   1]\n",
      " [  0  43  68 530 121  40  69  12  11   3   3  12  56   4   6   0   2   0\n",
      "    1   1]\n",
      " [  1  39  64 191 427  41  72  12  21   5   3  14  57   4   7   2   3   0\n",
      "    0   0]\n",
      " [  4 119 114  35  32 569  41   2   9   3   3  23  10   6  11   2   3   0\n",
      "    1   1]\n",
      " [  3  15  18  41  27  11 744  29  22   9  12   6  24   2   8   0   0   0\n",
      "    4   0]\n",
      " [  6   4   3   9  15   7  42 702  99  14   4  13  28   2  11   0  22   3\n",
      "    6   0]\n",
      " [  9   8   4   2   9   6  35 115 728  19   6   5  16   6   5   1  19   0\n",
      "    3   0]\n",
      " [  5   8   3   1   2   1  19   3  13 820  96   6   0   2   3   0   3   2\n",
      "    6   1]\n",
      " [  5   3   3   0   2   3   6   1  17  59 891   0   0   2   4   0   2   0\n",
      "    1   0]\n",
      " [  9  19  30  17  13  32   9   4  15   4   1 741  20   6   9   0  37   3\n",
      "   18   4]\n",
      " [  3  54  26  76  53  24  46  36  15   8   5  32 573  11  18   0   2   0\n",
      "    2   0]\n",
      " [ 18  16   5   5   5  10   9   7  28  11   3   4  13 814  19   2   4   3\n",
      "   12   2]\n",
      " [ 15  29   6   2  12  10  12  11  36  13  10  20  14  19 749   3   9   1\n",
      "   14   2]\n",
      " [ 70   9   4   3   2   2   4   0  11  10   4   3   0  11   7 803  13  19\n",
      "    9  13]\n",
      " [ 11   2   5   4   2   2  11   9  29  13   5  25   5  11   5   5 693  28\n",
      "   43   2]\n",
      " [ 33   6   1   1   1   2   2   2   9  11   2  12   2   8   8  18  27 766\n",
      "   24   5]\n",
      " [ 37   3   5   3   0   3   5   5  18  19   7  20   2  14  14  11 133  42\n",
      "  430   4]\n",
      " [102   2   2   1   3   1   0   1  15   8   3   5   0  17   9 202  68  23\n",
      "   20 146]]\n"
     ]
    }
   ],
   "source": [
    "lsa_experiment(train_x, train_y, clf_type=\"random_forest\", splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [18:42, 140.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- CLASSIFIER: xgboost ----\n",
      "acc: 0.7401040008489865\n",
      "[[501   3   1   0   4   0   2   3  14   5   1  10   0  13  11  93  25  32\n",
      "   24  57]\n",
      " [  6 615  72  30  30 100  25   4   9   7   2  14  21   4  21   3   1   4\n",
      "    2   3]\n",
      " [  5  65 651  79  33  87  15   4   7   4   1   9  10   1   9   1   2   0\n",
      "    2   0]\n",
      " [  0  47  77 561 141  28  42  11   5   2   4  10  42   6   1   1   2   0\n",
      "    2   0]\n",
      " [  1  38  48 138 571  24  51  10  11   7   2   4  45   5   3   2   1   1\n",
      "    1   0]\n",
      " [  0 106  73  31  32 668  18   1   7   0   3  10  12   3  10   5   3   3\n",
      "    2   1]\n",
      " [  2  13  15  39  17   8 748  32  25   7   9   3  39   1   9   3   1   1\n",
      "    2   1]\n",
      " [  2   7   7   8   7   5  25 747  87   5   7   8  36   5   5   4  14   1\n",
      "    9   1]\n",
      " [  5   9   3   4   9   3  29  83 783   6   2   3  12   7   6   1  11   4\n",
      "   15   1]\n",
      " [  6  10   3   5   0   4  14   2  13 848  60   3   5   2   3   0   1   3\n",
      "    9   3]\n",
      " [  2   4   0   0   4   4   2   0  11  56 892   3   2   2   5   0   0   3\n",
      "    7   2]\n",
      " [  8  23  11   6   9  21   3   1   4   0   0 826  17   3   5   1  27   4\n",
      "   20   2]\n",
      " [  2  40  12  50  51  17  26  16   6   5   3  13 712   6  15   1   6   0\n",
      "    3   0]\n",
      " [ 11  12   1   5   9   4   2   3  15  10   1   3  11 867  12   7   3   2\n",
      "   12   0]\n",
      " [ 10  27   3   3   4   6   8   6  14   6   5  14  18  13 815   5   5   1\n",
      "   18   6]\n",
      " [ 55   2   3   2   4   3   1   2   1   7   2   1   0  10   4 809   8  15\n",
      "   10  58]\n",
      " [ 15   2   3   4   2   3   6   4  11   4   3  20   9   7   8   3 724  14\n",
      "   55  13]\n",
      " [ 11   3   0   0   2   0   2   1   4   5   1   4   1   5   4  12  25 810\n",
      "   43   7]\n",
      " [ 29   4   4   1   0   2   3   7   8  13   4  19   0   8  11   8  93  21\n",
      "  536   4]\n",
      " [ 92   0   2   0   2   3   0   1   9   1   2   2   0  15   9 133  57  12\n",
      "   24 264]]\n"
     ]
    }
   ],
   "source": [
    "lsa_experiment(train_x, train_y, clf_type=\"xgboost\", splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = Probability(iterations=100)\n",
    "#spike_train_x = encoder.encode_dataset(newsgroups_vectors_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snn_experiment(data_x, train_y, clf_type=\"regression\", splits=4, shape=(10, 10, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
