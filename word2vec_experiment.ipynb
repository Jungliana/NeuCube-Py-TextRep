{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import torch\n",
    "\n",
    "from experiments.experiment import snn_experiment, lsa_experiment\n",
    "from experiments.preprocess import Word2VecPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "cats = ['comp.graphics', 'sci.med']  #, 'talk.politics.guns']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "text_prep = Word2VecPrep(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSubject: Re: Need polygon splitting algo...\\nOrganization: University of Southern California, Los Angeles, CA\\nLines: 25\\nDistribution: world\\nNNTP-Posting-Host: caspian.usc.edu\\nKeywords: polygons, splitting, clipping\\n\\n\\nIn article <1qvq4b$r4t@wampyr.cc.uow.edu.au>, g9134255@wampyr.cc.uow.edu.au (Coronado Emmanuel Abad) writes:\\n|> \\n|> The idea is to clip one polygon using another polygon (not\\n|> necessarily rectangular) as a window.  My problem then is in\\n|> finding out all the new vertices of the resulting \"subpolygons\"\\n|> from the first one.  Is this simply a matter of extending the\\n|> usual algorithm whereby each of the edges of one polygon is checked\\n|> against another polygon???  Is there a simpler way??\\n|> \\n|> Comments welcome.\\n|> \\n|> Noel.\\n\\n\\tIt depends on what kind of the polygons. \\n\\tConvex - simple, concave - trouble, concave with loop(s)\\n\\tinside - big trouble.\\n\\n\\tOf cause, you can use the box test to avoid checking\\n\\teach edges. According to my experience, there is not\\n\\ta simple way to go. The headache stuff is to deal with\\n\\tthe special cases, for example, the overlapped lines.\\n\\n\\tYeh\\n\\tUSC\\n',\n",
       " 'From: jim.zisfein@factory.com (Jim Zisfein) \\nSubject: Need advice with doctor-patient relationship problem\\nDistribution: world\\nOrganization: Invention Factory\\'s BBS - New York City, NY - 212-274-8298v.32bis\\nReply-To: jim.zisfein@factory.com (Jim Zisfein) \\nLines: 13\\n\\nML> From: libman@hsc.usc.edu (Marlena Libman)\\nML> I need advice with a situation which occurred between me and a physican\\nML> which upset me.\\n\\nML> My questions: (1) Should I continue to have this doctor manage my care?\\n\\nThat\\'s easy:  No.  You wouldn\\'t take your computer into a repair\\nshop where they were rude to you, even if they were competent in\\ntheir business.  Why would you take your own body into a \"repair\\nshop\" where the \"repairman\" has such a bad attitude?\\n---\\n . SLMR 2.1 . E-mail: jim.zisfein@factory.com (Jim Zisfein)\\n                                              \\n',\n",
       " \"From: stefan@lis.e-technik.tu-muenchen.de (Stefan Eckart)\\nSubject: dmpeg10.zip info: Another DOS MPEG decoder/player posted\\nKeywords: MPEG, DOS\\nReply-To: stefan@lis.e-technik.tu-muenchen.de\\nOrganization: Technische Universitaet Muenchen, Germany\\nLines: 74\\n\\n\\nI have posted a DOS MPEG decoder/player to alt.binaries.pictures.utilities.\\n\\nHere is a short description and some technical information, taken from the\\naccompanying documentation:\\n\\n\\n                              DMPEG V1.0\\n\\n                       Public Domain MPEG decoder\\n\\n                           by Stefan Eckart\\n\\n\\n0. Features\\n===========\\n\\nDMPEG/DMPLAY is another MPEG decoder/player for the PC:\\n\\n\\n - decodes (nearly) the full MPEG video standard\\n   (I,P,B frames, frame size up to at least 352x240 supported)\\n\\n - saves decoded sequence in 8 or 24bit raw file for later display\\n\\n - optional on-screen display during decoding (requires VGA)\\n\\n - several dithering options: ordered dither, Floyd-Steinberg, grayscale\\n\\n - color-space selection\\n\\n - runs under DOS, 640KB RAM, no MS-Windows required\\n\\n - very compact (small code / small data models, 16 bit arithmetic)\\n\\n - real time display of the raw file by a separate player for\\n   VGA and many Super-VGAs\\n\\n...\\n\\n4. Technical information\\n========================\\n\\nThe player is a rather straightforward implementation of the MPEG spec [1].\\nThe IDCT is based on the Chen-Wang 13 multiplication algorithm [2]\\n(not quite the optimum, I know). Blocks with not more than eight non-zero\\ncoefficients use a non-separated direct multiply-accumulate 2D-IDCT\\n(sounds great, doesn't it?), which turned out to be faster than a 'fast'\\nalgorithm in this (quite common) case. Dithering is pretty standard. Main\\ndifference to the Berkeley decoder (except for the fewer number of supported\\nalgorithms) is the use of 256 instead of 128 colors, the (default) option to\\nuse a restricted color-space and the implementation of a color saturation\\ndominant ordered dither. This leads to a significantly superior quality of\\nthe dithered image (I claim, judge yourself).\\n\\nRestricted color-space means that the U and V components are clipped to\\n+/-0.25 (instead of +/-0.5) and the display color-space points are distributed\\nover this restricted space. Since the distance between color-space points\\nis thus reduced by a factor of two, the color resolution is doubled at the\\nexpense of not being able to represent fully saturated colors.\\n\\nSaturation dominant ordered dither is a method by which a color, lying\\nsomewhere between the points of the display color space, is approximated\\nby primarily alternating between two points of constant hue instead of\\nconstant saturation. This yields subjectivly better quality due to the\\nlower sensitivity of the human viewing system to saturation changes than\\nto hue changes (the same reasoning as used by the PAL TV standard to improve\\non NTSC). The improvement is particularly visible in dark brown or redish\\nareas.\\n\\n...\\n\\n--\\nStefan Eckart, stefan@lis.e-technik.tu-muenchen.de\\n\",\n",
       " \"From: dougb@comm.mot.com (Doug Bank)\\nSubject: Re: Blood Cholesterol -  Gabe Mirkin's advice\\nReply-To: dougb@ecs.comm.mot.com\\nOrganization: Motorola Land Mobile Products Sector\\nNntp-Posting-Host: 145.1.146.35\\nLines: 29\\n\\nIn article <1pka0uINNnqa@mojo.eng.umd.edu>, georgec@eng.umd.edu (George B. Clark) writes:\\n|> Forget about total cholesterol when assessing health risk factors.\\n|> Instead, use a relationship between LDL and HDL cholesterol:\\n|> \\n|> If your LDL is       You need an HDL of at least\\n|> \\n|>       90                 35\\n|>      100                 45\\n|>      110                 50\\n|>      120                 55\\n|>      130                 60\\n|>      140                 70\\n\\nGee, what do I do?  My LDL is only 50-60. (and my HDL is only 23-25)\\nI must be risking something, but Is it the same risk as those with \\nvery high LDL?\\n\\n|> If your triglycerides are above 300, and your HDL is below 30, the\\n|> drug of choice is gemfibrozil (Lopid) taken as a 600mg tablet\\n|> thirty minutes before your morning and evening meals.\\n\\nWhat about exercise and a low-fat diet?  What are the long-term \\neffects of this drug?\\n\\n-- \\nDoug Bank                       Private Systems Division\\ndougb@ecs.comm.mot.com          Motorola Communications Sector\\ndougb@nwu.edu                   Schaumburg, Illinois\\ndougb@casbah.acns.nwu.edu       708-576-8207                    \\n\",\n",
       " 'From: ranjan@cs.ubc.ca (Vishwa Ranjan)\\nSubject: Complex (i.e. with real and imaginary parts) bio-medical images..\\nOrganization: Computer Science, University of B.C., Vancouver, B.C., Canada\\nLines: 7\\nDistribution: world\\nNNTP-Posting-Host: ironduke.cs.ubc.ca\\n\\nAre  complex  bio-medical  images  available  anywhere on the net for \\nexperimentation?  By complex I mean that every sampled data point has \\na magnitude and phase information both. \\n\\nThanks for any pointers,\\n--Vishwa\\n\\n',\n",
       " \"From: edb9140@tamsun.tamu.edu (E.B.)\\nSubject: POV problems with tga outputs\\nOrganization: Texas A&M University, College Station, TX\\nLines: 9\\nDistribution: world\\nNNTP-Posting-Host: tamsun.tamu.edu\\n\\nI can't fiqure this out.  I have properly compiled pov on a unix machine\\nrunning SunOS 4.1.3  The problem is that when I run the sample .pov files and\\nuse the EXACT same parameters when compiling different .tga outputs.  Some\\nof the .tga's are okay, and other's are unrecognizable by any software.\\n\\nHelp!\\ned\\nedb9140@tamsun.tamu.edu\\n\\n\",\n",
       " 'From: Daniel.Prince@f129.n102.z1.calcom.socal.com (Daniel Prince)\\nSubject: Acutane, Fibromyalgia Syndrome and CFS\\nLines: 11\\n\\n To: nyeda@cnsvax.uwec.edu (David Nye)\\n\\nThere is a person on the FIDO CFS echo who claims that he was \\ncured of CFS by taking accutane.  He also claims that you are \\nusing it in the treatment of Fibromyalgia Syndrome.  Are you \\nusing accutane in the treatment of Fibromyalgia Syndrome?  Have \\nyou used it for CFS?  Have you gotten good results with it?  Are \\nyou aware of any double blind studies on the use of accutane in \\nthese conditions?  Thank you in advance for all replies.\\n\\n... I think they should rename Waco TX to Wacko TX!\\n',\n",
       " \"From: gavin@krypton.asd.sgi.com (Gavin Bell)\\nSubject: Re: Surface normal orientations\\nOrganization: Silicon Graphics, Inc.  Mountain View, CA\\nLines: 38\\nNNTP-Posting-Host: krypton.asd.sgi.com\\n\\nIn <1pscti$aqe@travis.csd.harris.com> srp@travis.csd.harris.com (Stephen Pietrowicz) writes:\\n>How do you go about orienting all normals in the same direction, given a \\n>set of points, edges and faces?\\n\\nThis algorithm works well for me:\\n\\nAlgorithm to attempt to find outward-facing normals:\\n---------------------------------------------------\\nFirst, mark all faces as UNKNOWN.\\n\\nThen create an edge dictionary that allows you to find all of the\\nfaces sharing a given edge (where an edge is two integers representing\\nthe two shared vertices).\\n\\nPick an arbitrary face and mark it COUNTER_CLOCKWISE.  Using the edge\\ndictionary, orient all surrounding faces based on the orientation of\\nthis face.  And recurse for all surrounding faces, consistently\\norienting the entire surface.\\n\\nFind the average of the vertices in this surface.  Using that point,\\ncalculate a volume measurement, taking into account the face's\\norientation.  If the volume turns out to be positive, assume the faces\\nare oriented correctly.  If it is negative, reverse their orientations\\n(mark them CLOCKWISE).\\n\\nIf any faces are still UNKNOWN after this, choose another face\\nand go through the algorithm again.\\n\\nAt the end, faces marked CLOCKWISE must have their indices reversed\\nbefore facet normals are found.\\n\\n(Note: if you are running on Silicon Graphics machines and buy the\\nIRIS Inventor 3D toolkit developers package you have the source to\\nthis algorithm-- see /usr/src/Inventor/tools/ivnorm/.  If you're\\nnot... sorry, I can't give out the source, and even if I could it\\nrelies heavily on Inventor).\\n--\\n--gavin     (gavin@sgi.com,  (415)390-1024)\\n\",\n",
       " \"From: mstern@lindsay.Princeton.EDU (Marlene J. Stern)\\nSubject: Recurrent Respiratory Papillomatosis\\nOriginator: news@nimaster\\nNntp-Posting-Host: lindsay.princeton.edu\\nOrganization: Princeton University\\nDistribution: nj\\nLines: 43\\n\\n\\nWe will be holding a bake and craft sale at Communiversity in Princeton on  \\nNassau Street, Saturday April 24th 12-4 p.m. to benefit the Recurrent  \\nRespiratory Papillomatosis Foundation, a nonprofit foundation established to  \\nencourage research toward a cure for Recurrent Respiratory Papillomatosis.  Our  \\nthree year old daughter suffers from this disease.  Below is a press release  \\nthat appeared in local newspapers.  Hope you can join us.\\n\\n\\nOn Saturday, April 24 as part of Communiversity in Princeton, a local family  \\nwill be having a bake and craft sale to raise money for and create public  \\nawareness about a rare disease called Recurrent Respiratory Papillomatosis.\\n\\nBill and Marlene Stern's daughter Lindsay is afflicted with this disease  \\ncharacterized by tumors attacking the inside of the larynx, vocal cords and  \\ntrachea.  Caused by a virus, the tumors grow, block the air passages and would  \\nlead to death from suffocation without continual surgery to remove the growths.   \\nThree year old Lindsay has undergone 11 operations thus far since her diagnosis  \\nlast year and faces the prospect of over a hundred operations throughout her  \\nlifetime.  \\n\\nEven though the disease is hardly a household word, it has affected the lives  \\nof enough people to inspire the formation of the Recurrent Respiratory  \\nPapillomatosis Foundation,  a non-profit foundation whose goals are to provide  \\nsupport for patients and families by networking patients and publishing a  \\nnewsletter, enhance  awareness of RRP at the local and national level, and aid  \\nin the prevention, cure, and treatment.\\n\\nSince medical researchers know that the virus causing the disease is similar to  \\nthose viruses causing warts, they feel a cure would be within reach if money  \\nwere available for research.  Because RRP is rare, it not only gets scant  \\nattention but also paltry funds to search for a cure.  Part of the RRP  \\nFoundation's mission is to change that. \\n\\nAnyone interested in contributing items to the bake and craft sale, please call  \\nMarlene or Bill at 609-890-0502.  Monetary donations can be made at the  \\nFoundation's booth during Communiversity, April 24th, 12 to 4 p.m., in downtown  \\nPrinceton, or sent directly to:\\n\\n\\t\\t\\tThe Recurrent Respiratory Foundation\\n\\t                50 Wesleyan Drive\\n\\t                Hamilton Sq., NJ  08690.\\nThanks   mstern@lindsay.princeton.edu\\n\",\n",
       " 'From: markl@hunan.rastek.com (Mark Larsen)\\nSubject: Re: Ray tracer for ms-dos?\\nOrganization: Rastek Corporation, Huntsville, AL\\nLines: 32\\n\\nIn article <1r1cqiINNje8@srvr1.engin.umich.edu> tdawson@llullaillaco.engin.umich.edu (Chris Herringshaw) writes:\\n>\\n>Sorry for the repeat of this request, but does anyone know of a good\\n>free/shareware program with which I can create ray-traces and save\\n>them as bit-mapped files?  (Of course if there is such a thing =)\\n>\\n>Thanks in advance\\n>\\n>Daemon\\n\\nThere are 2 books published by M&T BOOKS that come with C source code on\\nfloppies.  They are:\\n\\nProgramming In 3 Dimensions, 3-D Graphics, Ray Traycing, and Animation\\nby: Christopher D. Watkins and Larry Sharp.\\n\\nPhotorealism and Ray Tracing in C\\nby: Christopher D. Watkins, Stephen B. Coy, and Mark Finlay.\\n\\nI have the first book and it is a great intro to 3-D, Ray Tracing and\\nAnimation.  Most of the programs are on the disk compiled and ready to run.\\n\\nI have only glanced at the second book but it also appears to be good.\\n\\nHope this helps!\\nMark Larsen\\n\\n---------------------------------------------------------------------------\\nmarkl@hunan.rastek.com\\n\\n\"This R2 unit has a bad motivator!\"\\n   - Luke, Star Wars\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\Documents\\Moje dokumenty\\Studia\\Praca Magisterska\\NeuCube-Py-TextRep\\experiments\\preprocess.py:85: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  train_x = tensor(newsgroups_vectors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = text_prep.preprocess_dataset(newsgroups_train, avg=True)\n",
    "train_x.to(device)\n",
    "train_y.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 20.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.9634974533106961\n",
      "[[574  10]\n",
      " [ 33 561]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lsa_experiment(train_x, train_y, clf_type=\"regression\", splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsa_experiment(train_x, train_y, clf_type=\"random_forest\", splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lsa_experiment(train_x, train_y, clf_type=\"xgboost\", splits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = Probability(iterations=100)\n",
    "#spike_train_x = encoder.encode_dataset(newsgroups_vectors_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_train_x, spike_train_y = text_prep.preprocess_dataset(newsgroups_train, avg=False, max_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = (spike_train_x > -0.1) & (spike_train_x < 0.1)\n",
    "mask = spike_train_x >= 0.25\n",
    "data_x = torch.where(mask, torch.tensor(1), torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "data_x.to(device)\n",
    "spike_train_y.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [10:12, 122.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.8514431239388794\n",
      "[[505  79]\n",
      " [ 96 498]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snn_experiment(data_x, spike_train_y, clf_type=\"regression\", splits=5, shape=(4, 4, 4), res_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [10:06, 121.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.8752122241086587\n",
      "[[507  77]\n",
      " [ 70 524]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snn_experiment(data_x, spike_train_y, clf_type=\"regression\", splits=5, shape=(5, 5, 5), res_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [10:14, 122.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.8938879456706282\n",
      "[[529  55]\n",
      " [ 70 524]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snn_experiment(data_x, spike_train_y, clf_type=\"regression\", splits=5, shape=(6, 6, 6), res_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [10:15, 123.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.9015280135823429\n",
      "[[530  54]\n",
      " [ 62 532]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snn_experiment(data_x, spike_train_y, clf_type=\"regression\", splits=5, shape=(5, 6, 7), res_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [10:34, 126.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- CLASSIFIER: regression ----\n",
      "acc: 0.9142614601018676\n",
      "[[537  47]\n",
      " [ 54 540]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "snn_experiment(data_x, spike_train_y, clf_type=\"regression\", splits=5, shape=(8, 8, 8), res_train=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
